{
  "chunk-eedeb3a863bd155a0a6328eb91b29a23": {
    "tokens": 214,
    "content": "Title: embeddings/index/0/index.faiss\n\nHi, \r\n\r\nI'm trying to run the OpenScholar search API using the code in `retriever/api/serve_pes2o.py`. I've successfully set up the environment and can see the embeddings files (passages_*.pkl) in the embeddings directory. I've downloaded the embeddings from huggingface (https://huggingface.co/datasets/OpenScholar/OpenScholar-DataStore-V3/tree/main/embeddings).\r\n\r\nHowever, I'm encountering an error when the system tries to load the FAISS index. The configuration file indicates that the system is looking for FAISS index files at `embeddings/index/0/index.faiss`:\r\n\r\n failed: could not open /zhuminjun/OpenScholar/embeddings/index/0/index.faiss for reading: No such file or directory\r\n\r\nThank you for your help!\r\n\r\nEnvironment:\r\n- Following main branch of OpenScholar\r\n- Have embeddings files (passages_*.pkl) downloaded from huggingface\r\n- Running serve_pes2o.py from retriever/api/",
    "chunk_order_index": 0,
    "full_doc_id": "doc-eedeb3a863bd155a0a6328eb91b29a23"
  },
  "chunk-929d3719c32a00b5697d213605da1fc8": {
    "tokens": 160,
    "content": "Title: Local usage requirements?\n\nHi! I would love to try running this framework, and to compare it to other STEM RAG tools.\r\n I have limited local compute and storage (~ 64 GB RAM, < 100GB free SSD storage, 12 GB 4080 GPU) - given that, will the framework run locally using just the semantic scholar search for retrieval, or is the use of the entire retrieval framework (~45M papers + indexing) unavoidable? I want to try running just it and some of the sources, or even just the few documents retrieved by search, as a lightweight comparison. \r\n(I would rather not try setting up a new project, then find that it's mandatory to use the huge peS2o datastore +- if I can't even run it).\r\n\r\nThanks very much!",
    "chunk_order_index": 0,
    "full_doc_id": "doc-929d3719c32a00b5697d213605da1fc8"
  },
  "chunk-a120747bd1499c7abf036d5339d3bc77": {
    "tokens": 12,
    "content": "Title: Can the author provide some examples for the input_file",
    "chunk_order_index": 0,
    "full_doc_id": "doc-a120747bd1499c7abf036d5339d3bc77"
  },
  "chunk-7d7b0e85a44a65f4986b68850d44ad73": {
    "tokens": 73,
    "content": "Title: search() in user_search_apis.py\n\nThanks for the great work. \r\n\r\nI noticed that the `search()` method (line 280) used in the `search_google_non_restricted()` function in user_search_apis.py seems to be missing its import. Could you kindly clarify which method is being used and where it’s defined?\r\n\r\nThanks!",
    "chunk_order_index": 0,
    "full_doc_id": "doc-7d7b0e85a44a65f4986b68850d44ad73"
  },
  "chunk-8f6ffcf80fc6ee22155d5023b18c823d": {
    "tokens": 194,
    "content": "Title: How to identify training examples (y0 → F) &  (yt−1, ft → yt)\n\nThank you for sharing this work. My questions are just to check my own understanding of the referenced datasets.\r\n\r\nIn the paper it mentions\r\n\r\n**Data mixing and training.** From this synthetic pipeline, we generate three types of training\r\ndata: answer generation (x → y), feedback generation (y0 → F), and feedback incorporation\r\n(yt−1, ft → yt).\r\n\r\n--\r\nAre these three types of data available in https://huggingface.co/datasets/OpenScholar/OS_Train_Data ?\r\nCan you recommend a way to analyse the dataset to identify which of these types a sample belongs to?\r\nI've manually reviewed a low number; and they have been answer generation (x → y). \r\n\r\nI would be interested in finding training examples for (y0 → F) &  (yt−1, ft → yt)\r\n\r\nThanks",
    "chunk_order_index": 0,
    "full_doc_id": "doc-8f6ffcf80fc6ee22155d5023b18c823d"
  },
  "chunk-b488c3dbb955edb9264cc65ce80e8145": {
    "tokens": 50,
    "content": "Title: OpenScholar_Train_Data URL return 404\n\nHi. It's great work.\r\n\r\nHowever, I can not find dataset in\r\n\r\nhttps://huggingface.co/OpenScholar/OpenScholar_Train_Data\r\n\r\nCould you kindly provide correct URL.\r\n\r\nThanks,",
    "chunk_order_index": 0,
    "full_doc_id": "doc-b488c3dbb955edb9264cc65ce80e8145"
  },
  "chunk-768bae22e0a75094dfad8f3411802320": {
    "tokens": 43,
    "content": "Name: Zack Roach \nContact: 405-820-7910 \nRole: Sr. Director of Land  \nOrganization: Rausch Coleman Homes \nLinkedIn: https://www.linkedin.com/in/zroach/",
    "chunk_order_index": 0,
    "full_doc_id": "doc-768bae22e0a75094dfad8f3411802320"
  },
  "chunk-3c42c878fe09e1792e27d97eff81b7a1": {
    "tokens": 211,
    "content": "Title: The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare\n\nAuthors: Souren Pashangpour, Goldie Nejat\n\nSummary: The potential use of large language models (LLMs) in healthcare robotics can\nhelp address the significant demand put on healthcare systems around the world\nwith respect to an aging demographic and a shortage of healthcare\nprofessionals. Even though LLMs have already been integrated into medicine to\nassist both clinicians and patients, the integration of LLMs within healthcare\nrobots has not yet been explored for clinical settings. In this perspective\npaper, we investigate the groundbreaking developments in robotics and LLMs to\nuniquely identify the needed system requirements for designing health specific\nLLM based robots in terms of multi modal communication through human robot\ninteractions (HRIs), semantic reasoning, and task planning. Furthermore, we\ndiscuss the ethical issues, open challenges, and potential future research\ndirections for this emerging innovative field.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-3c42c878fe09e1792e27d97eff81b7a1"
  },
  "chunk-799e6187dbce567a1501543c23cb8716": {
    "tokens": 358,
    "content": "Title: NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs\n\nAuthors: Maria Antoniak, Aakanksha Naik, Carla S. Alvarado, Lucy Lu Wang, Irene Y. Chen\n\nSummary: Ethical frameworks for the use of natural language processing (NLP) are\nurgently needed to shape how large language models (LLMs) and similar tools are\nused for healthcare applications. Healthcare faces existing challenges\nincluding the balance of power in clinician-patient relationships, systemic\nhealth disparities, historical injustices, and economic constraints. Drawing\ndirectly from the voices of those most affected, and focusing on a case study\nof a specific healthcare setting, we propose a set of guiding principles for\nthe use of NLP in maternal healthcare. We led an interactive session centered\non an LLM-based chatbot demonstration during a full-day workshop with 39\nparticipants, and additionally surveyed 30 healthcare workers and 30 birthing\npeople about their values, needs, and perceptions of NLP tools in the context\nof maternal health. We conducted quantitative and qualitative analyses of the\nsurvey results and interactive discussions to consolidate our findings into a\nset of guiding principles. We propose nine principles for ethical use of NLP\nfor maternal healthcare, grouped into three themes: (i) recognizing contextual\nsignificance (ii) holistic measurements, and (iii) who/what is valued. For each\nprinciple, we describe its underlying rationale and provide practical advice.\nThis set of principles can provide a methodological pattern for other\nresearchers and serve as a resource to practitioners working on maternal health\nand other healthcare fields to emphasize the importance of technical nuance,\nhistorical context, and inclusive design when developing NLP technologies for\nclinical use.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-799e6187dbce567a1501543c23cb8716"
  },
  "chunk-12a8ca6dbed2511139a35915b9f9143e": {
    "tokens": 312,
    "content": "Title: Developing Healthcare Language Model Embedding Spaces\n\nAuthors: Niall Taylor, Dan Schofield, Andrey Kormilitzin, Dan W Joyce, Alejo Nevado-Holgado\n\nSummary: Pre-trained Large Language Models (LLMs) often struggle on out-of-domain\ndatasets like healthcare focused text. We explore specialized pre-training to\nadapt smaller LLMs to different healthcare datasets. Three methods are\nassessed: traditional masked language modeling, Deep Contrastive Learning for\nUnsupervised Textual Representations (DeCLUTR), and a novel pre-training\nobjective utilizing metadata categories from the healthcare settings. These\nschemes are evaluated on downstream document classification tasks for each\ndataset, with additional analysis of the resultant embedding spaces.\nContrastively trained models outperform other approaches on the classification\ntasks, delivering strong performance from limited labeled data and with fewer\nmodel parameter updates required. While metadata-based pre-training does not\nfurther improve classifications across the datasets, it yields interesting\nembedding cluster separability. All domain adapted LLMs outperform their\npublicly available general base LLM, validating the importance of\ndomain-specialization. This research illustrates efficient approaches to\ninstill healthcare competency in compact LLMs even under tight computational\nbudgets, an essential capability for responsible and sustainable deployment in\nlocal healthcare settings. We provide pre-training guidelines for specialized\nhealthcare LLMs, motivate continued inquiry into contrastive objectives, and\ndemonstrates adaptation techniques to align small LLMs with privacy-sensitive\nmedical tasks.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-12a8ca6dbed2511139a35915b9f9143e"
  },
  "chunk-00a20072cec518c59f6dc4560ece9090": {
    "tokens": 402,
    "content": "Title: A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics\n\nAuthors: Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria\n\nSummary: The utilization of large language models (LLMs) in the Healthcare domain has\ngenerated both excitement and concern due to their ability to effectively\nrespond to freetext queries with certain professional knowledge. This survey\noutlines the capabilities of the currently developed LLMs for Healthcare and\nexplicates their development process, with the aim of providing an overview of\nthe development roadmap from traditional Pretrained Language Models (PLMs) to\nLLMs. Specifically, we first explore the potential of LLMs to enhance the\nefficiency and effectiveness of various Healthcare applications highlighting\nboth the strengths and limitations. Secondly, we conduct a comparison between\nthe previous PLMs and the latest LLMs, as well as comparing various LLMs with\neach other. Then we summarize related Healthcare training data, training\nmethods, optimization strategies, and usage. Finally, the unique concerns\nassociated with deploying LLMs in Healthcare settings are investigated,\nparticularly regarding fairness, accountability, transparency and ethics. Our\nsurvey provide a comprehensive investigation from perspectives of both computer\nscience and Healthcare specialty. Besides the discussion about Healthcare\nconcerns, we supports the computer science community by compiling a collection\nof open source resources, such as accessible datasets, the latest\nmethodologies, code implementations, and evaluation benchmarks in the Github.\nSummarily, we contend that a significant paradigm shift is underway,\ntransitioning from PLMs to LLMs. This shift encompasses a move from\ndiscriminative AI approaches to generative AI approaches, as well as a shift\nfrom model-centered methodologies to data-centered methodologies. Also, we\ndetermine that the biggest obstacle of using LLMs in Healthcare are fairness,\naccountability, transparency and ethics.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-00a20072cec518c59f6dc4560ece9090"
  },
  "chunk-07aa59a7143ac23ee4e5f88ace78ace0": {
    "tokens": 348,
    "content": "Title: Large language models in healthcare and medical domain: A review\n\nAuthors: Zabir Al Nazi, Wei Peng\n\nSummary: The deployment of large language models (LLMs) within the healthcare sector\nhas sparked both enthusiasm and apprehension. These models exhibit the\nremarkable capability to provide proficient responses to free-text queries,\ndemonstrating a nuanced understanding of professional medical knowledge. This\ncomprehensive survey delves into the functionalities of existing LLMs designed\nfor healthcare applications, elucidating the trajectory of their development,\nstarting from traditional Pretrained Language Models (PLMs) to the present\nstate of LLMs in healthcare sector. First, we explore the potential of LLMs to\namplify the efficiency and effectiveness of diverse healthcare applications,\nparticularly focusing on clinical language understanding tasks. These tasks\nencompass a wide spectrum, ranging from named entity recognition and relation\nextraction to natural language inference, multi-modal medical applications,\ndocument classification, and question-answering. Additionally, we conduct an\nextensive comparison of the most recent state-of-the-art LLMs in the healthcare\ndomain, while also assessing the utilization of various open-source LLMs and\nhighlighting their significance in healthcare applications. Furthermore, we\npresent the essential performance metrics employed to evaluate LLMs in the\nbiomedical domain, shedding light on their effectiveness and limitations.\nFinally, we summarize the prominent challenges and constraints faced by large\nlanguage models in the healthcare sector, offering a holistic perspective on\ntheir potential benefits and shortcomings. This review provides a comprehensive\nexploration of the current landscape of LLMs in healthcare, addressing their\nrole in transforming medical applications and the areas that warrant further\nresearch and development.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-07aa59a7143ac23ee4e5f88ace78ace0"
  },
  "chunk-746a2e949136cf455bcbb45e15640c1b": {
    "tokens": 389,
    "content": "Title: Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in Internet of Medical Things: A Diffusion-based Contract Approach\n\nAuthors: Cheng Su, Jinbo Wen, Jiawen Kang, Yonghua Wang, Yuanjia Su, Hudan Pan, Zishao Zhong, M. Shamim Hossain\n\nSummary: Secure data management and effective data sharing have become paramount in\nthe rapidly evolving healthcare landscape, especially with the growing\nintegration of the Internet of Medical Things (IoMT). The rise of generative\nartificial intelligence has further elevated Multi-modal Large Language Models\n(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.\nMLLMs can support multi-modal inputs and generate diverse types of content by\nleveraging large-scale training on vast amounts of multi-modal data. However,\ncritical challenges persist in developing medical MLLMs, including security and\nfreshness issues of healthcare data, affecting the output quality of MLLMs. To\nthis end, in this paper, we propose a hybrid Retrieval-Augmented Generation\n(RAG)-empowered medical MLLM framework for healthcare data management. This\nframework leverages a hierarchical cross-chain architecture to facilitate\nsecure data training. Moreover, it enhances the output quality of MLLMs through\nhybrid RAG, which employs multi-modal metrics to filter various unimodal RAG\nresults and incorporates these retrieval results as additional inputs to MLLMs.\nAdditionally, we employ age of information to indirectly evaluate the data\nfreshness impact of MLLMs and utilize contract theory to incentivize healthcare\ndata holders to share their fresh data, mitigating information asymmetry during\ndata sharing. Finally, we utilize a generative diffusion model-based deep\nreinforcement learning algorithm to identify the optimal contract for efficient\ndata sharing. Numerical results demonstrate the effectiveness of the proposed\nschemes, which achieve secure and efficient healthcare data management.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-746a2e949136cf455bcbb45e15640c1b"
  },
  "chunk-f71d71575b67372237c79f027531a812": {
    "tokens": 244,
    "content": "Title: AI as a Medical Ally: Evaluating ChatGPT's Usage and Impact in Indian Healthcare\n\nAuthors: Aryaman Raina, Prateek Mishra, Harshit goyal, Dhruv Kumar\n\nSummary: This study investigates the integration and impact of Large Language Models\n(LLMs), like ChatGPT, in India's healthcare sector. Our research employs a dual\napproach, engaging both general users and medical professionals through surveys\nand interviews respectively. Our findings reveal that healthcare professionals\nvalue ChatGPT in medical education and preliminary clinical settings, but\nexercise caution due to concerns about reliability, privacy, and the need for\ncross-verification with medical references. General users show a preference for\nAI interactions in healthcare, but concerns regarding accuracy and trust\npersist. The study underscores the need for these technologies to complement,\nnot replace, human medical expertise, highlighting the importance of developing\nLLMs in collaboration with healthcare providers. This paper enhances the\nunderstanding of LLMs in healthcare, detailing current usage, user trust, and\nimprovement areas. Our insights inform future research and development,\nunderscoring the need for ethically compliant, user-focused LLM advancements\nthat address healthcare-specific challenges.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-f71d71575b67372237c79f027531a812"
  },
  "chunk-e4c2a113f1d3a4f01418e92c10b2f918": {
    "tokens": 168,
    "content": "Title: Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework\n\nAuthors: Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo\n\nSummary: This paper explores the application of large language models (LLMs) in\nnursing and elderly care, focusing on AI-driven patient monitoring and\ninteraction. We introduce a novel Chinese nursing dataset and implement\nincremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to\nenhance LLM performance in specialized tasks. Using LangChain, we develop a\ndynamic nursing assistant capable of real-time care and personalized\ninterventions. Experimental results demonstrate significant improvements,\npaving the way for AI-driven solutions to meet the growing demands of\nhealthcare in aging populations.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-e4c2a113f1d3a4f01418e92c10b2f918"
  },
  "chunk-4d11a4bc08b074c441bcb51f64b06c68": {
    "tokens": 173,
    "content": "Title: The Role of Language Models in Modern Healthcare: A Comprehensive Review\n\nAuthors: Amna Khalid, Ayma Khalid, Umar Khalid\n\nSummary: The application of large language models (LLMs) in healthcare has gained\nsignificant attention due to their ability to process complex medical data and\nprovide insights for clinical decision-making. These models have demonstrated\nsubstantial capabilities in understanding and generating natural language,\nwhich is crucial for medical documentation, diagnostics, and patient\ninteraction. This review examines the trajectory of language models from their\nearly stages to the current state-of-the-art LLMs, highlighting their strengths\nin healthcare applications and discussing challenges such as data privacy,\nbias, and ethical considerations. The potential of LLMs to enhance healthcare\ndelivery is explored, alongside the necessary steps to ensure their ethical and\neffective integration into medical practice.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-4d11a4bc08b074c441bcb51f64b06c68"
  },
  "chunk-292f82c8f02f7979158f415bd80b08fa": {
    "tokens": 262,
    "content": "Title: Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime Healthcare Access\n\nAuthors: Shaoshan Liu, Yuzhang Huang, Leiyu Shi\n\nSummary: We are facing a global healthcare crisis today as the healthcare cost is ever\nclimbing, but with the aging population, government fiscal revenue is ever\ndropping. To create a more efficient and effective healthcare system, three\ntechnical challenges immediately present themselves: healthcare access,\nhealthcare equity, and healthcare efficiency. An autonomous mobile clinic\nsolves the healthcare access problem by bringing healthcare services to the\npatient by the order of the patient's fingertips. Nevertheless, to enable a\nuniversal autonomous mobile clinic network, a three-stage technical roadmap\nneeds to be achieved: In stage one, we focus on solving the inequity challenge\nin the existing healthcare system by combining autonomous mobility and\ntelemedicine. In stage two, we develop an AI doctor for primary care, which we\nfoster from infancy to adulthood with clean healthcare data. With the AI\ndoctor, we can solve the inefficiency problem. In stage three, after we have\nproven that the autonomous mobile clinic network can truly solve the target\nclinical use cases, we shall open up the platform for all medical verticals,\nthus enabling universal healthcare through this whole new system.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-292f82c8f02f7979158f415bd80b08fa"
  },
  "chunk-efb627453d9e7b92041c1cd80ca462e7": {
    "tokens": 192,
    "content": "Title: Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective\n\nAuthors: Yue Zhou, Barbara Di Eugenio, Lu Cheng\n\nSummary: This paper studies the performance of large language models (LLMs),\nparticularly regarding demographic fairness, in solving real-world healthcare\ntasks. We evaluate state-of-the-art LLMs with three prevalent learning\nframeworks across six diverse healthcare tasks and find significant challenges\nin applying LLMs to real-world healthcare tasks and persistent fairness issues\nacross demographic groups. We also find that explicitly providing demographic\ninformation yields mixed results, while LLM's ability to infer such details\nraises concerns about biased health predictions. Utilizing LLMs as autonomous\nagents with access to up-to-date guidelines does not guarantee performance\nimprovement. We believe these findings reveal the critical limitations of LLMs\nin healthcare fairness and the urgent need for specialized research in this\narea.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-efb627453d9e7b92041c1cd80ca462e7"
  },
  "chunk-4274827395862dc00e22130db721f004": {
    "tokens": 201,
    "content": "Title: Understanding the concerns and choices of public when using large language models for healthcare\n\nAuthors: Yunpeng Xiao, Kyrie Zhixuan Zhou, Yueqing Liang, Kai Shu\n\nSummary: Large language models (LLMs) have shown their potential in biomedical fields.\nHowever, how the public uses them for healthcare purposes such as medical Q\\&A,\nself-diagnosis, and daily healthcare information seeking is under-investigated.\nThis paper adopts a mixed-methods approach, including surveys (N=214) and\ninterviews (N=17) to investigate how and why the public uses LLMs for\nhealthcare. We found that participants generally believed LLMs as a healthcare\ntool have gained popularity, and are often used in combination with other\ninformation channels such as search engines and online health communities to\noptimize information quality. Based on the findings, we reflect on the ethical\nand effective use of LLMs for healthcare and propose future research\ndirections.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-4274827395862dc00e22130db721f004"
  },
  "chunk-17857a680273de6a1b5d622606d046d5": {
    "tokens": 399,
    "content": "Title: Aloe: A Family of Fine-tuned Open Healthcare LLMs\n\nAuthors: Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Jordi Bayarri-Planas, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Lucia Urcelay-Ganzabal, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés Dario Garcia-Gasulla\n\nSummary: As the capabilities of Large Language Models (LLMs) in healthcare and\nmedicine continue to advance, there is a growing need for competitive\nopen-source models that can safeguard public interest. With the increasing\navailability of highly competitive open base models, the impact of continued\npre-training is increasingly uncertain. In this work, we explore the role of\ninstruct tuning, model merging, alignment, red teaming and advanced inference\nschemes, as means to improve current open models. To that end, we introduce the\nAloe family, a set of open medical LLMs highly competitive within its scale\nrange. Aloe models are trained on the current best base models (Mistral, LLaMA\n3), using a new custom dataset which combines public data sources improved with\nsynthetic Chain of Thought (CoT). Aloe models undergo an alignment phase,\nbecoming one of the first few policy-aligned open healthcare LLM using Direct\nPreference Optimization, setting a new standard for ethical performance in\nhealthcare LLMs. Model evaluation expands to include various bias and toxicity\ndatasets, a dedicated red teaming effort, and a much-needed risk assessment for\nhealthcare LLMs. Finally, to explore the limits of current LLMs in inference,\nwe study several advanced prompt engineering strategies to boost performance\nacross benchmarks, yielding state-of-the-art results for open healthcare 7B\nLLMs, unprecedented at this scale.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-17857a680273de6a1b5d622606d046d5"
  },
  "chunk-b646ae28e259ac4d6938eeed118a3938": {
    "tokens": 216,
    "content": "Title: Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI\n\nAuthors: Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy\n\nSummary: Large language models have proliferated across multiple domains in as short\nperiod of time. There is however hesitation in the medical and healthcare\ndomain towards their adoption because of issues like factuality, coherence, and\nhallucinations. Give the high stakes nature of healthcare, many researchers\nhave even cautioned against its usage until these issues are resolved. The key\nto the implementation and deployment of LLMs in healthcare is to make these\nmodels trustworthy, transparent (as much possible) and explainable. In this\npaper we describe the key elements in creating reliable, trustworthy, and\nunbiased models as a necessary condition for their adoption in healthcare.\nSpecifically we focus on the quantification, validation, and mitigation of\nhallucinations in the context in healthcare. Lastly, we discuss how the future\nof LLMs in healthcare may look like.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-b646ae28e259ac4d6938eeed118a3938"
  },
  "chunk-1bca4db130670b433d98f151556ae2a8": {
    "tokens": 249,
    "content": "Title: Rapid Integration of LLMs in Healthcare Raises Ethical Concerns: An Investigation into Deceptive Patterns in Social Robots\n\nAuthors: Robert Ranisch, Joschka Haltaufderheide\n\nSummary: Conversational agents are increasingly used in healthcare, and the\nintegration of Large Language Models (LLMs) has significantly enhanced their\ncapabilities. When integrated into social robots, LLMs offer the potential for\nmore natural interactions. However, while LLMs promise numerous benefits, they\nalso raise critical ethical concerns, particularly around the issue of\nhallucinations and deceptive patterns. In this case study, we observed a\ncritical pattern of deceptive behavior in commercially available LLM-based care\nsoftware integrated into robots. The LLM-equipped robot falsely claimed to have\nmedication reminder functionalities. Not only did these systems assure users of\ntheir ability to manage medication schedules, but they also proactively\nsuggested this capability, despite lacking it. This deceptive behavior poses\nsignificant risks in healthcare environments, where reliability is paramount.\nOur findings highlights the ethical and safety concerns surrounding the\ndeployment of LLM-integrated robots in healthcare, emphasizing the need for\noversight to prevent potentially harmful consequences for vulnerable\npopulations.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-1bca4db130670b433d98f151556ae2a8"
  },
  "chunk-2aadcc3b57ec385ba885bee646eb8f19": {
    "tokens": 271,
    "content": "Title: HealthQ: Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations\n\nAuthors: Ziyu Wang, Hao Li, Di Huang, Amir M. Rahmani\n\nSummary: In digital healthcare, large language models (LLMs) have primarily been\nutilized to enhance question-answering capabilities and improve patient\ninteractions. However, effective patient care necessitates LLM chains that can\nactively gather information by posing relevant questions. This paper presents\nHealthQ, a novel framework designed to evaluate the questioning capabilities of\nLLM healthcare chains. We implemented several LLM chains, including\nRetrieval-Augmented Generation (RAG), Chain of Thought (CoT), and reflective\nchains, and introduced an LLM judge to assess the relevance and informativeness\nof the generated questions. To validate HealthQ, we employed traditional\nNatural Language Processing (NLP) metrics such as Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) and Named Entity Recognition (NER)-based set\ncomparison, and constructed two custom datasets from public medical note\ndatasets, ChatDoctor and MTS-Dialog. Our contributions are threefold: we\nprovide the first comprehensive study on the questioning capabilities of LLMs\nin healthcare conversations, develop a novel dataset generation pipeline, and\npropose a detailed evaluation methodology.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-2aadcc3b57ec385ba885bee646eb8f19"
  },
  "chunk-e22ae5b44344a4bf0b458c7cf8a975f4": {
    "tokens": 390,
    "content": "Title: Are Large Language Models True Healthcare Jacks-of-All-Trades? Benchmarking Across Health Professions Beyond Physician Exams\n\nAuthors: Zheheng Luo, Chenhan Yuan, Qianqian Xie, Sophia Ananiadou\n\nSummary: Recent advancements in Large Language Models (LLMs) have demonstrated their\npotential in delivering accurate answers to questions about world knowledge.\nDespite this, existing benchmarks for evaluating LLMs in healthcare\npredominantly focus on medical doctors, leaving other critical healthcare\nprofessions underrepresented. To fill this research gap, we introduce the\nExaminations for Medical Personnel in Chinese (EMPEC), a pioneering large-scale\nhealthcare knowledge benchmark in traditional Chinese. EMPEC consists of\n157,803 exam questions across 124 subjects and 20 healthcare professions,\nincluding underrepresented occupations like Optometrists and Audiologists. Each\nquestion is tagged with its release time and source, ensuring relevance and\nauthenticity. We conducted extensive experiments on 17 LLMs, including\nproprietary, open-source models, general domain models and medical specific\nmodels, evaluating their performance under various settings. Our findings\nreveal that while leading models like GPT-4 achieve over 75\\% accuracy, they\nstill struggle with specialized fields and alternative medicine. Surprisingly,\ngeneral-purpose LLMs outperformed medical-specific models, and incorporating\nEMPEC's training data significantly enhanced performance. Additionally, the\nresults on questions released after the models' training cutoff date were\nconsistent with overall performance trends, suggesting that the models'\nperformance on the test set can predict their effectiveness in addressing\nunseen healthcare-related queries. The transition from traditional to\nsimplified Chinese characters had a negligible impact on model performance,\nindicating robust linguistic versatility. Our study underscores the importance\nof expanding benchmarks to cover a broader range of healthcare professions to\nbetter assess the applicability of LLMs in real-world healthcare scenarios.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-e22ae5b44344a4bf0b458c7cf8a975f4"
  },
  "chunk-6327688eb460934dc39564501475c8ec": {
    "tokens": 379,
    "content": "Title: Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review\n\nAuthors: Mingze Yuan, Peng Bao, Jiajia Yuan, Yunhao Shen, Zifan Chen, Yi Xie, Jie Zhao, Yang Chen, Li Zhang, Lin Shen, Bin Dong\n\nSummary: With the rapid development of artificial intelligence, large language models\n(LLMs) have shown promising capabilities in mimicking human-level language\ncomprehension and reasoning. This has sparked significant interest in applying\nLLMs to enhance various aspects of healthcare, ranging from medical education\nto clinical decision support. However, medicine involves multifaceted data\nmodalities and nuanced reasoning skills, presenting challenges for integrating\nLLMs. This paper provides a comprehensive review on the applications and\nimplications of LLMs in medicine. It begins by examining the fundamental\napplications of general-purpose and specialized LLMs, demonstrating their\nutilities in knowledge retrieval, research support, clinical workflow\nautomation, and diagnostic assistance. Recognizing the inherent multimodality\nof medicine, the review then focuses on multimodal LLMs, investigating their\nability to process diverse data types like medical imaging and EHRs to augment\ndiagnostic accuracy. To address LLMs' limitations regarding personalization and\ncomplex clinical reasoning, the paper explores the emerging development of\nLLM-powered autonomous agents for healthcare. Furthermore, it summarizes the\nevaluation methodologies for assessing LLMs' reliability and safety in medical\ncontexts. Overall, this review offers an extensive analysis on the\ntransformative potential of LLMs in modern medicine. It also highlights the\npivotal need for continuous optimizations and ethical oversight before these\nmodels can be effectively integrated into clinical practice. Visit\nhttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying\nGitHub repository containing latest papers.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-6327688eb460934dc39564501475c8ec"
  },
  "chunk-d44c81a7d86687e4ddc194cba22e8cd5": {
    "tokens": 334,
    "content": "Title: Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health\n\nAuthors: Bo Wen, Raquel Norel, Julia Liu, Thaddeus Stappenbeck, Farhana Zulkernine, Huamin Chen\n\nSummary: The rapid advancements in large language models (LLMs) have opened up new\nopportunities for transforming patient engagement in healthcare through\nconversational AI. This paper presents an overview of the current landscape of\nLLMs in healthcare, specifically focusing on their applications in analyzing\nand generating conversations for improved patient engagement. We showcase the\npower of LLMs in handling unstructured conversational data through four case\nstudies: (1) analyzing mental health discussions on Reddit, (2) developing a\npersonalized chatbot for cognitive engagement in seniors, (3) summarizing\nmedical conversation datasets, and (4) designing an AI-powered patient\nengagement system. These case studies demonstrate how LLMs can effectively\nextract insights and summarizations from unstructured dialogues and engage\npatients in guided, goal-oriented conversations. Leveraging LLMs for\nconversational analysis and generation opens new doors for many\npatient-centered outcomes research opportunities. However, integrating LLMs\ninto healthcare raises important ethical considerations regarding data privacy,\nbias, transparency, and regulatory compliance. We discuss best practices and\nguidelines for the responsible development and deployment of LLMs in healthcare\nsettings. Realizing the full potential of LLMs in digital health will require\nclose collaboration between the AI and healthcare professionals communities to\naddress technical challenges and ensure these powerful tools' safety, efficacy,\nand equity.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-d44c81a7d86687e4ddc194cba22e8cd5"
  },
  "chunk-6f7b612d7fc75191e42324c3b3d3dd8a": {
    "tokens": 290,
    "content": "Title: Healthcare Copilot: Eliciting the Power of General LLMs for Medical Consultation\n\nAuthors: Zhiyao Ren, Yibing Zhan, Baosheng Yu, Liang Ding, Dacheng Tao\n\nSummary: The copilot framework, which aims to enhance and tailor large language models\n(LLMs) for specific complex tasks without requiring fine-tuning, is gaining\nincreasing attention from the community. In this paper, we introduce the\nconstruction of a Healthcare Copilot designed for medical consultation. The\nproposed Healthcare Copilot comprises three main components: 1) the Dialogue\ncomponent, responsible for effective and safe patient interactions; 2) the\nMemory component, storing both current conversation data and historical patient\ninformation; and 3) the Processing component, summarizing the entire dialogue\nand generating reports. To evaluate the proposed Healthcare Copilot, we\nimplement an auto-evaluation scheme using ChatGPT for two roles: as a virtual\npatient engaging in dialogue with the copilot, and as an evaluator to assess\nthe quality of the dialogue. Extensive results demonstrate that the proposed\nHealthcare Copilot significantly enhances the capabilities of general LLMs for\nmedical consultations in terms of inquiry capability, conversational fluency,\nresponse accuracy, and safety. Furthermore, we conduct ablation studies to\nhighlight the contribution of each individual module in the Healthcare Copilot.\nCode will be made publicly available on GitHub.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-6f7b612d7fc75191e42324c3b3d3dd8a"
  },
  "chunk-9cdeff9ce328faea27e0adb387c3473d": {
    "tokens": 264,
    "content": "Paul Okafor \n2900 Oak Tree Ave. Apt 3204-C,  \nNorman. \nOklahoma. \n73072 \n \nDear Hiring Committee, \nI am writing to express my keen interest in the Product Associate, Machine Learning, Data \nModernization and Quality position at JP Morgan Chase. With over four years of experience \nin data management, predictive analytics, and business intelligence, I am confident that I \nhave the skills and experience to be successful in this role. \nIn my previous role as a Graduate Research Assistant at the University of Oklahoma, I \ndeveloped advanced data pipelines and predictive models that improved process efficiency \nby over 20%. I am also proficient in Python, R, SQL, and Power BI, and I have a s trong track \nrecord of managing complex datasets and creating intuitive dashboards. \nI am particularly drawn to this role's emphasis on database design and data visualization. I \nam confident that I can use my skills in these areas to ensure data accuracy and usability, \nand to meet the dynamic needs of the university. \nI am excited about the prospect of contributing to your team's success, and I am confident \nthat I can make a significant contribution to the university. Thank you for your time and \nconsideration.  \nSincerely, \nPaul Okafor",
    "chunk_order_index": 0,
    "full_doc_id": "doc-9cdeff9ce328faea27e0adb387c3473d"
  },
  "chunk-fd8645be6d41a3adc71fe1b7f7e681fb": {
    "tokens": 246,
    "content": "2985\n(3107\n(3107\nIs Mill\nExpl\nBard\nChatc\nMail\nFiverr\nAli | P\nGrade\nFY24\nFall 20\nThe V\nDEI E\nWebi\nC\nfiverr com/v4/payments/new?paymentSessionID=6565043f85943100238f30f9\n0\n1\nCLx]\n* & 0\nfiven:\nOrder Details\n2\nConfirm &\nSubmit Requirements\nBilling information\nFursam wtrz\nwill code, debug and\nPrjofkarindt\nteach in cpp, java and\npython\nYour invoice will be issued according to the\nAdd details\ndetails listed here.\ncode, debug and teach in cpp,\n835\npaultwizzy\njava and python\nNigeria\nEnter promo code\nPayment Options\nService fee\n84.43\nPayPal\nVAT\n$2.95\nTotal\n842.38\nRemember for future payments\nTotal delivery time\ndays\nPayPal\nSSL Secure Payment\n519F\n3.04 PM\nSunny\nSearch\nNew\nd) 0\n11/27/2023\nPay",
    "chunk_order_index": 0,
    "full_doc_id": "doc-fd8645be6d41a3adc71fe1b7f7e681fb"
  },
  "chunk-13f6ea367d78bfb9591ab3e9b32f199d": {
    "tokens": 334,
    "content": "(c) (4 points) Summation of every variable xij over j that belongs to the set J and i that belongs to the\nset I, if the pair ( i, j) belongs to the set of pairs A. Solution: P\nj∈J,i∈I:(i,j)∈A xij\n6. (14 points) Expand the expressions:\n(a) (7 points) P\nj∈{0,1,...,12}:j mod 2=0j Solution: 2 + 4 + 6 + 8 + 10 + 12\n(b) (7 points) Let\nN = {1, 2, 3, 4}, A= {(1, 2), (2, 3), (2, 4), (3, 4), (2, 1)}, D= {3}, S= {1, 2}, T = {4}\nbi =\n\n\n\nαi i ∈ S\nβi i ∈ D\n0 i ∈ T\n∀ i ∈ N\nExpand:\nX\nj∈N:(i,j)∈A\nxij −\nX\nj∈N:(j,i)∈A\nxji = bi ∀ i ∈ N\nSolution:\nx12 − x21 = α1\nx23 + x24 + x21 − x12 = α2\nx34 − x23 = β3\n−x24 − x34 = 0\n3",
    "chunk_order_index": 0,
    "full_doc_id": "doc-13f6ea367d78bfb9591ab3e9b32f199d"
  },
  "chunk-34f48dc0df89619d6972bb68d0b5a66b": {
    "tokens": 27,
    "content": "The Greeks, just to keep in mind:\nFigure 1: Retrieved from https://www.instagram.com/joshi_physics_classes/\n4",
    "chunk_order_index": 0,
    "full_doc_id": "doc-34f48dc0df89619d6972bb68d0b5a66b"
  },
  "chunk-d87f29fe57f853d7e875e98f24f6f4b1": {
    "tokens": 406,
    "content": "ISE 4623/5023: Deterministic Systems Models / Systems Optimiza-\ntion University of Oklahoma School of Industrial and Systems Engi-\nneering Fall 2024\nIndividual Assignment 1: Linear Algebra Basics and Mathematical\nNotation\n1. (18 points) Let\nA =\n\u00144 1 8\n2 −7 5\n\u0015\n, B=\n\n\n−9 7\n1 5\n8 3\n\n\nSolve:\n(a) (3 points) AB\n(b) (3 points) BA\n(c) (3 points) −B\n(d) (3 points) B − A\n(e) (3 points) AT\n(f) (3 points) −BT B\nSolution:\n(a)\nAB =\n\u001429 57\n15 −6\n\u0015\n(b)\nBA =\n\n\n−22 −58 −37\n14 −34 33\n38 −13 79\n\n\n(c)\n−B =\n\n\n9 −7\n−1 −5\n−8 −3\n\n\n(d) B − A: Not possible, different dimensions\n(e)\nAT =\n\n\n4 2\n1 −7\n8 5\n\n\n(f)\n−BT B =\n\u0014−146 34\n34 −83\n\u0015\n2. (21 points) If possible, solve for x and y. If they can’t be computed, give a brief explanation of why:\n(a) (7 points)\n3x + y = 5\n8x + 5y = 2\nSolution:\ny = 5 − 3\n25 − 15x + 8x = 2\nx = 23/7, y= −34/7\n1",
    "chunk_order_index": 0,
    "full_doc_id": "doc-d87f29fe57f853d7e875e98f24f6f4b1"
  },
  "chunk-4b360189455a063d99146226a4a17468": {
    "tokens": 545,
    "content": "(b) (7 points)\n15x + 5y = 40\n3x − y = 8\nSolution:\ny = 3x − 8.\n30x − 40 = 40.\nx = 8/3, y= 0.\n(c) (7 points)\n2x − 24y = 42\n−x + 12y = −20\nSolution: No solutions\n3. (20 points) Let:\nC =\n\u0014 3 −2\n12 −8\n\u0015\n, D=\n\u0014−1 4\n6 −8\n\u0015\n, E=\n\n\n1 2 3\n4 5 6\n7 8 9\n\nF =\n\n\n−3 5 9\n8 −2 5\n1 −2 14\n\n\nSolve:\n(a) (5 points) C−1\n(b) (5 points) D−1\n(c) (5 points) E−1\n(d) (5 points) F−1\nSolution:\n(a)\nC−1 : No solution\n(b)\nD−1 :\n\u0014 0.5 0 .25\n0.375 0 .0625\n\u0015\n(c)\nE−1 : No solution\n(d)\nF−1 =\n\n\n18\n607\n88\n607 − 43\n607107\n607\n51\n607 − 87\n60714\n607\n1\n607\n34\n607\n\n\n4. (15 points) Translate into words:\n(a) (5 points) P\nj∈R j Solution: Summation of all real numbers.\n(b) (5 points) P\nj∈Z+|j mod 5=0j Solution: Summation of all integer possitive numbers multiples of 5.\n(c) (5 points) P40\nj=1\nj∈Z\nj Solution: Summation of all integers from 1 to 40.\n5. (12 points) Translate into mathematical expression:\n(a) (4 points) Summation of every element j over the set J such that the element is odd. Solution:P\nj∈J|j mod 2!=0j\n(b) (4 points) Summation of every variable xij over j that belongs to the set J for all i that belongs to\nthe set I. Solution: P\nj∈J xij ∀ i ∈ I\n2",
    "chunk_order_index": 0,
    "full_doc_id": "doc-4b360189455a063d99146226a4a17468"
  }
}